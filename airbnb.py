# -*- coding: utf-8 -*-
"""airbnb.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ah2rlpyGBlThJvstD8Pro4s4OIx22r4e
"""

!pip install pymongo

pip install pandas numpy matplotlib seaborn pymongo

pip install --upgrade pymongo

!pip freeze pymongo

!pip uninstall pymongo

!pip uninstall bson

pip install --upgrade pandas

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pymongo

client = pymongo.MongoClient("mongodb+srv://rakul1999:Rakul3004@cluster0.rylnoat.mongodb.net/?retryWrites=true&w=majority")
db = client.sample_airbnb
collection = db.listingsAndReviews

data =[]
for i in collection.find():
  data.append(i)

data

pd.set_option('display.max_columns', 500)

frame=pd.DataFrame(data)
frame.columns = frame.columns.str.strip()

frame.columns = frame.columns.str.strip()

columns_to_drop =['listing_url','summary','interaction','last_scraped','calendar_last_scraped','first_review','last_review','cleaning_fee','images']
frame.drop(columns=columns_to_drop, inplace=True)

frame

frame.to_csv('frame.csv', index=False)

# """_id: An identifier for the listing.
# listing_url: The URL or link to the listing on a website or platform.
# name: The name or title of the listing.
# summary: A brief summary or description of the property.
# space: Information about the space or interior of the property.
# description: A more detailed description of the property.
# neighborhood_overview: Information about the neighborhood or area where the property is located.
# notes: Any additional notes or comments about the listing.
# transit: Details about public transportation options near the property.
# access: Information about guest access to the property.
# interaction: Details about how the host interacts with guests.
# house_rules: Any rules or guidelines for guests staying at the property.
# property_type: The type of property (e.g., apartment, house, villa).
# room_type: The type of room or accommodation (e.g., private room, entire place).
# bed_type: The type of bed(s) available (e.g., queen, king, sofa bed).
# minimum_nights: The minimum number of nights required for booking.
# maximum_nights: The maximum number of nights a guest can stay.
# cancellation_policy: The policy governing cancellations for the booking.
# last_scraped: The date when the listing data was last collected.
# calendar_last_scraped: The date when the availability calendar data was last collected.
# first_review: The date of the first guest review.
# last_review: The date of the most recent guest review.
# accommodates: The maximum number of guests the property can accommodate.
# bedrooms: The number of bedrooms in the property.
# beds: The number of beds in the property.
# number_of_reviews: The total number of guest reviews.
# bathrooms: The number of bathrooms in the property.
# amenities: A list of amenities or features provided in the property.
# price: The nightly price for renting the property.
# security_deposit: The amount of security deposit required.
# cleaning_fee: The fee for cleaning services.
# extra_people: The cost for additional guests beyond the base number.
# guests_included: The number of guests included in the base price.
# images: Information about images or photos of the property.
# host: Information about the host of the property.
# address: The address or location of the property.
# availability: Information about the availability of the property.
# review_scores: Scores related to guest reviews.
# reviews: Additional information or statistics about reviews.
# weekly_price: The price for a weekly stay.
# monthly_price: The price for a monthly stay.
# reviews_per_month: The average number of reviews received per month."""

frame1=pd.read_csv('frame.csv')
frame1

frame1.columns = frame1.columns.str.strip()

columns_to_drop =['listing_url','space','description','neighborhood_overview','notes','transit','summary','house_rules','access','security_deposit','interaction','last_scraped','calendar_last_scraped','first_review','last_review','cleaning_fee','images','cleaning_fee']
frame1.drop(columns=columns_to_drop, inplace=True)

frame1

frame1.isnull().sum()

frame1['bedrooms'].fillna(frame1['bedrooms'].mean(), inplace=True)
frame1['beds'].fillna(frame1['beds'].mean(), inplace=True)
frame1['bathrooms'].fillna(frame1['bathrooms'].mean(), inplace=True)
frame1['weekly_price'].fillna(frame1['weekly_price'].mean(), inplace=True)
frame1['monthly_price'].fillna(frame1['monthly_price'].mean(), inplace=True)
frame1['reviews_per_month'].fillna(frame1['reviews_per_month'].mean(), inplace=True)

frame1

frame1['neighborhood_overview'].fillna('Not available', inplace=True)
frame1

frame1['name'].fillna(frame1['name'].mode()[0], inplace=True)

frame1

# List of columns to remove
columns_to_remove = ['host', 'address', 'availability', 'review_scores', 'reviews']

# Use the drop method to remove the specified columns
df = frame1.drop(columns=columns_to_remove)

# Print the updated DataFrame
print(df)

df

duplicate_rowss= df[df.duplicated()]
duplicate_rowss

df.isnull().sum()

df.to_csv('data.csv', index=False)

frame.to_csv('frame.csv', index=False)

frame['_id']

frame['_id'].isnull().sum()

frame1.to_csv('frame1.csv', index=False)

hosts=pd.DataFrame(frame['host'])
hosts

# host = pd.DataFrame(b)
hosts=pd.DataFrame(frame['host'])

# Extract 'host_id' and 'host_name' from 'host' dictionary
hosts['host_id'] = hosts['host'].apply(lambda x: x['host_id'])
hosts['host_url'] = hosts['host'].apply(lambda x: x['host_url'])
hosts['host_name'] = hosts['host'].apply(lambda x: x['host_name'])
hosts['host_location'] = hosts['host'].apply(lambda x: x['host_location'])
hosts['host_about'] = hosts['host'].apply(lambda x: x['host_about'])
hosts['host_response_time'] = hosts['host'].apply(lambda x: x.get('host_response_time'))
hosts['host_thumbnail_url'] = hosts['host'].apply(lambda x: x['host_thumbnail_url'])
hosts['host_picture_url'] = hosts['host'].apply(lambda x: x['host_picture_url'])
hosts['host_neighbourhood'] = hosts['host'].apply(lambda x: x['host_neighbourhood'])
hosts['host_response_rate'] = hosts['host'].apply(lambda x: x.get('host_response_rate'))
hosts['host_is_superhost'] = hosts['host'].apply(lambda x: x['host_is_superhost'])
hosts['host_has_profile_pic'] = hosts['host'].apply(lambda x: x['host_has_profile_pic'])
hosts['host_identity_verified'] = hosts['host'].apply(lambda x: x['host_identity_verified'])
hosts['host_listings_count'] = hosts['host'].apply(lambda x: x['host_listings_count'])
hosts['host_total_listings_count'] = hosts['host'].apply(lambda x: x['host_total_listings_count'])
hosts['host_total_listings_count'] = hosts['host'].apply(lambda x: x['host_total_listings_count'])
hosts['host_verifications'] = hosts['host'].apply(lambda x: x['host_verifications'][0])

# Drop the original 'host' column if not needed
hosts.drop(columns=['host'], inplace=True)

hosts.to_csv('hosts_csv.csv', index=False)

condition = hosts['host_response_rate'] == 'unknown'
hosts.loc[condition, 'host_response_rate'] = 0

hosts



hosts.info()

hosts.describe()

plt.boxplot(hosts["host_response_rate"])

plt.boxplot(hosts["host_listings_count"])

Q1 = hosts['host_listings_count'].quantile(0.25)
Q3 = hosts['host_listings_count'].quantile(0.75)
IQR = Q3 - Q1

# Define the lower and upper bounds for outlier detection
lower_bound = Q1 - (1.5 * IQR)
upper_bound = Q3 + (1.5 * IQR)


lower_bound ,upper_bound

#print(outliers)

median_value = hosts['host_listings_count'].median()
median_value

# Impute outliers with median value
median_value = hosts['host_listings_count'].median()
hosts['host_listings_count_imputed'] = hosts['host_listings_count'].apply(lambda x: median_value if (x < lower_bound or x > upper_bound) else x)

# Create box plots for original and imputed data
plt.boxplot([hosts['host_listings_count'], hosts['host_listings_count_imputed']], labels=['Original', 'Imputed'])
plt.ylabel('Host Listings Count')
plt.title('Effect of Imputation on Outliers')
plt.show()

plt.boxplot(hosts["host_total_listings_count"])

Q1 = hosts['host_total_listings_count'].quantile(0.25)
Q3 = hosts['host_total_listings_count'].quantile(0.75)
IQR = Q3 - Q1

# Define the lower and upper bounds for outlier detection
lower_bound = Q1 - (1.5 * IQR)
upper_bound = Q3 + (1.5 * IQR)


lower_bound ,upper_bound

#print(outliers)

median_value = hosts['host_total_listings_count'].median()
median_value

# Impute outliers with median value
median_value = hosts['host_total_listings_count'].median()
hosts['host_listings_count_imputed'] = hosts['host_total_listings_count'].apply(lambda x: median_value if (x < lower_bound or x > upper_bound) else x)

# Create box plots for original and imputed data
plt.boxplot([hosts['host_total_listings_count'], hosts['host_listings_count_imputed']], labels=['Original', 'Imputed'])
plt.ylabel('Host Listings Count')
plt.title('Effect of Imputation on Outliers')
plt.show()

null_counts = hosts.isnull().sum()
null_counts

duplicate_rows = hosts[hosts.duplicated()]
duplicate_rows

unique_df = hosts.drop_duplicates()
unique_df

hosts

address_frame=pd.DataFrame(frame['address'])
address_frame

address_frame['street'] = address_frame['address'].apply(lambda x: x['street'])
address_frame['suburb'] = address_frame['address'].apply(lambda x: x['suburb'])
address_frame['government_area'] = address_frame['address'].apply(lambda x: x['government_area'])
address_frame['market'] = address_frame['address'].apply(lambda x: x['market'])
address_frame['country'] = address_frame['address'].apply(lambda x: x['country'])
address_frame['country_code'] = address_frame['address'].apply(lambda x: x['country_code'])
address_frame['is_location_exact'] = address_frame['address'].apply(lambda x: x['location']['is_location_exact'])
address_frame['type'] = address_frame['address'].apply(lambda x: x['location']['type'])
address_frame['Latitude'] = address_frame['address'].apply(lambda x: x['location']['coordinates'][1])
address_frame['Longitude'] = address_frame['address'].apply(lambda x: x['location']['coordinates'][0])
address_frame['is_location_exact'] = address_frame['address'].apply(lambda x: x['location']['is_location_exact'])
# Drop the original 'address' column if not needed
address_frame.drop(columns=['address'], inplace=True)

# Display the updated DataFrame
#print(address)

address_frame

address_frame.to_csv('address_csv.csv', index=False)

null_counts1 = address_frame.isnull().sum()
null_counts1

duplicate_rows1 = address_frame[address_frame.duplicated()]
duplicate_rows1





availabilitys = pd.DataFrame(frame['availability'])
availabilitys

availabilitys['availability_30'] = availabilitys['availability'].apply(lambda x: x['availability_30'])
availabilitys['availability_60'] = availabilitys['availability'].apply(lambda x: x['availability_60'])
availabilitys['availability_90'] = availabilitys['availability'].apply(lambda x: x['availability_90'])
availabilitys['availability_365'] = availabilitys['availability'].apply(lambda x: x['availability_365'])

availabilitys.drop(columns=['availability'], inplace=True)

availabilitys

availabilitys.to_csv('availabilitys_csv.csv', index=False)

images= pd.DataFrame(frame['images'])
images

# Extract image URLs from nested 'images' dictionary
#images['thumbnail_url'] = images['images'].apply(lambda x: x['thumbnail_url'])
#images['medium_url'] = images['images'].apply(lambda x: x['medium_url'])
images['picture_url'] = images['images'].apply(lambda x: x['picture_url'])
#images['xl_picture_url'] = images['images'].apply(lambda x: x['xl_picture_url'])

# Drop the original 'images' column if not needed
images.drop(columns=['images'], inplace=True)

images



review_scoress = pd.DataFrame(frame['review_scores'])
review_scoress

rating = pd.DataFrame(review_scoress)

# Extract review scores from nested 'review_scores' dictionary
rating['review_scores_accuracy'] = rating['review_scores'].apply(lambda x: x.get('review_scores_accuracy',0))
rating['review_scores_cleanliness'] = rating['review_scores'].apply(lambda x: x.get('review_scores_cleanliness',0))
rating['review_scores_checkin'] = rating['review_scores'].apply(lambda x: x.get('review_scores_checkin',0))
rating['review_scores_communication'] = rating['review_scores'].apply(lambda x: x.get('review_scores_communication',0))
rating['review_scores_location'] = rating['review_scores'].apply(lambda x: x.get('review_scores_location',0))
rating['review_scores_value'] = rating['review_scores'].apply(lambda x: x.get('review_scores_value',0))
rating['review_scores_rating'] = rating['review_scores'].apply(lambda x: x.get('review_scores_rating',0))

# Drop the original 'review_scores' column if not needed
rating.drop(columns=['review_scores'], inplace=True)

rating

rating.to_csv('rating_csv.csv', index=False)

c = pd.DataFrame(frame1['amenities'])
c

c.to_csv('amenities_csv', index=False)





import pandas as pd

# Specify the number of lines to skip at the end (1 line for the header)
skip_lines = 1

# Read the CSV file, skipping the specified number of lines at the end
host= pd.read_csv('hosts_csv.csv', skipfooter=skip_lines, engine='python')

# Now df should contain only the data rows and the header row as column names
host

# Check for null values in a specific column
null_values_in_column = host['host_total_listings_count'].isnull().sum()
null_values_in_column

# Check for null values in a specific column
null_values_in_column = host['host_location'].isnull()

# Filter the DataFrame to include only rows with null values in the specified column
rows_with_null_in_column = host[null_values_in_column]

# Display the rows with null values in the specified column
rows_with_null_in_column



host.isnull().sum()

columns_to_drop =['host_url','host_thumbnail_url','host_picture_url','host_identity_verified','host_has_profile_pic','host_listings_count','host_verifications']
host.drop(columns=columns_to_drop, inplace=True)

host

host['host_about'].fillna(host['host_about'].mode()[0], inplace=True)
host['host_response_time'].fillna(host['host_response_time'].mode()[0], inplace=True)
host['host_neighbourhood'].fillna(host['host_neighbourhood'].mode()[0], inplace=True)
host['host_response_rate'].fillna(host['host_response_rate'].mean(), inplace=True)
host['host_neighbourhood'].fillna(host['host_neighbourhood'].mode()[0], inplace=True)
host['host_is_superhost'].fillna(host['host_is_superhost'].mode()[0], inplace=True)
host['host_total_listings_count'].fillna(host['host_total_listings_count'].mean(), inplace=True)

host['host_location'].fillna('Not available' ,inplace=True)

host

host.to_csv('host_filter.csv', index=False)

import pandas as pd

# Specify the number of lines to skip at the end (1 line for the header)
skip_lines = 1

# Read the CSV file, skipping the specified number of lines at the end
address= pd.read_csv('address_csv.csv', skipfooter=skip_lines, engine='python')

# Now df should contain only the data rows and the header row as column names
address

# Custom function to fill NaN values in 'suburb' using 'market'
def fill_suburb_with_market(row):
    if pd.isna(row['suburb']):
        return row['market']
    else:
        return row['suburb']

# Apply the custom function to fill NaN values in 'suburb' column
address['suburb'] = address.apply(fill_suburb_with_market, axis=1)

address

# Check for null values in a specific column
null_values_in_column = address['market'].isnull()

# Filter the DataFrame to include only rows with null values in the specified column
rows_with_null_in_column1 = address[null_values_in_column]

# Display the rows with null values in the specified column
rows_with_null_in_column1

address.loc[576, 'market'] = "Waverly	"
address.loc[619, 'market'] = "Manhattan"
address.loc[640, 'market'] = "Not Available"
address.loc[654, 'market'] = "Downtown Montreal"
address.loc[775, 'market'] = "Sants-Montjuïc"
address.loc[791, 'market'] = "Kaua'i"

address['street'] = address['street'].str.split(',').str[0]

address['government_area'] = address['government_area'].str.split(',').str[0]

address['suburb'].fillna('Not Available', inplace=True)

address

missing_values = address.isnull().sum()
missing_values

duplicate_rows2 = address[address.duplicated()]
duplicate_rows2



address.to_csv('address_filter.csv', index=False)

import pandas as pd

# Specify the number of lines to skip at the end (1 line for the header)
skip_lines = 1

# Read the CSV file, skipping the specified number of lines at the end
amenities1= pd.read_csv('amenities_csv', skipfooter=skip_lines, engine='python')

# Now df should contain only the data rows and the header row as column names
amenities1

amenities1.isnull().sum()

missing_values2= amenities1.isnull().sum()
missing_values2

# import pandas as pd

# # Load your dataset into a pandas DataFrame
# data_1 = c

# # List of amenities you want to check for
# amenities_to_check = ['TV', 'Wifi', 'Air conditioning', 'Parking', 'Pool', 'Gym','Cable TV','Kitchen','Paid parking off premises','Smoking allowed','Pets allowed','Buzzer/wireless intercom','Heating','Family/kid friendly',
#  'Washer',
#  'First aid kit',
#  'Fire extinguisher',
#  'Essentials',
#  'Hangers',
#  'Hair dryer',
#  'Iron',
#  'Pack ’n Play/travel crib',
#  'Room-darkening shades',
#  'Hot water',
#  'Bed linens',
#  'Extra pillows and blankets',
#  'Microwave',
#  'Coffee maker',
#  'Refrigerator',
#  'Dishwasher',
#  'Dishes and silverware',
#  'Cooking basics',
#  'Oven',
#  'Stove',
#  'Cleaning before checkout',
#  'Waterfront','Laptop friendly workspace','Essentials''Wheelchair accessible','Elevator','Hot tub','Microwave','BBQ grill',
#  'Garden or backyard',
#  'Well-lit path to entrance',
#  'Disabled parking spot',
#  'Step-free access',
#  'Wide clearance to bed',
#  'Step-free access']

# # Check if 'amenities' column exists in the DataFrame
# if 'amenities' in data_1.columns:
#     # Create new columns for each amenity and encode them as True or False
#     for amenity in amenities_to_check:
#         data_1[amenity] = data_1['amenities'].apply(lambda x: amenity in x)

#     # Drop the original 'amenities' column
#     data_1.drop(columns=['amenities'], inplace=True)
# else:
#     print("The 'amenities' column does not exist in the dataset.")

# # Print the updated DataFrame
# #print(data_1)

import pandas as pd

# Assuming you have already loaded your dataset into a DataFrame named 'data_1'
data_1 = amenities1

# List of amenities you want to check for
amenities_to_check = ['TV', 'Wifi', 'Air conditioning', 'Parking', 'Pool', 'Gym','Cable TV','Kitchen','Paid parking off premises','Smoking allowed','Pets allowed','Buzzer/wireless intercom','Heating','Family/kid friendly',
 'Washer',
 'First aid kit',
 'Fire extinguisher',
 'Essentials',
 'Hangers',
 'Hair dryer',
 'Iron',
 'Pack ’n Play/travel crib',
 'Room-darkening shades',
 'Hot water',
 'Bed linens',
 'Extra pillows and blankets',
 'Microwave',
 'Coffee maker',
 'Refrigerator',
 'Dishwasher',
 'Dishes and silverware',
 'Cooking basics',
 'Oven',
 'Stove',
 'Cleaning before checkout',
 'Waterfront','Laptop friendly workspace','Essentials''Wheelchair accessible','Elevator','Hot tub','Microwave','BBQ grill',
 'Garden or backyard',
 'Well-lit path to entrance',
 'Disabled parking spot',
 'Step-free access',
 'Wide clearance to bed',
 'Step-free access']

# Check if 'amenities' column exists in the DataFrame
if 'amenities' in data_1.columns:
    # Create new columns for each amenity and encode them as "YES" or "NO"
    for amenity in amenities_to_check:
        data_1[amenity] = data_1['amenities'].apply(lambda x: "YES" if amenity in x else "NO")

    # Drop the original 'amenities' column
    data_1.drop(columns=['amenities'], inplace=True)
else:
    print("The 'amenities' column does not exist in the dataset.")

# Print the updated DataFrame
# print(data_1)

amenities_1 = pd.DataFrame(data_1)
amenities_1

duplicate_rows3= amenities_1[amenities_1.duplicated()]
duplicate_rows3

amenities_1.to_csv('amenities_filter.csv', index=False)

import pandas as pd

# Specify the number of lines to skip at the end (1 line for the header)
skip_lines = 1

# Read the CSV file, skipping the specified number of lines at the end
aval= pd.read_csv('availabilitys_csv.csv', skipfooter=skip_lines, engine='python')

# Now df should contain only the data rows and the header row as column names
aval

missing_values3 = aval.isnull().sum()
#print("Missing Values:")
missing_values3

duplicate_rows4= aval[aval.duplicated()]
duplicate_rows4

aval.to_csv('availability_filter.csv', index=False)

import pandas as pd

# Specify the number of lines to skip at the end (1 line for the header)
skip_lines = 0

# Read the CSV file, skipping the specified number of lines at the end
rat= pd.read_csv('rating_csv.csv', skipfooter=skip_lines, engine='python')

# Now df should contain only the data rows and the header row as column names
rat

rat.isnull().sum()

rat.duplicated().sum()

rat.to_csv('rating_filter.csv', index=False)